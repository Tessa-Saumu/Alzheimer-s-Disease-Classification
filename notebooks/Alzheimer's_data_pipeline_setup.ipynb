{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzhsNKQNA52L"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfAPP-sBHjSc"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKAJioKRG0fz"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive')\n",
        "#!unzip /content/drive/MyDrive/archive.zip -d /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzrOQO2eHmQW"
      },
      "source": [
        "## Define Data Splitting Function\n",
        "\n",
        "1. Split data 70/15/15 : Train/Validation/Test\n",
        "2. Define robust per-image normalization\n",
        "3. Create ImageDataGeneratory objects to efficiently load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "yvqT2v1CQUy6",
        "outputId": "063d9ff0-1d11-4da2-acc2-a6d9f4d5cae8"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# 1. Paths\n",
        "# ----------------------------\n",
        "SOURCE_DIR = r'/content/data/combined_images'\n",
        "OUTPUT_DIR = r'/content/data'\n",
        "\n",
        "CLASSES = [\n",
        "    'MildDemented',\n",
        "    'ModerateDemented',\n",
        "    'NonDemented',\n",
        "    'VeryMildDemented'\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Dataset split (run once)\n",
        "# ----------------------------\n",
        "def split_dataset():\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    for class_name in CLASSES:\n",
        "        class_dir = os.path.join(SOURCE_DIR, class_name)\n",
        "        images = [os.path.join(class_dir, f) for f in os.listdir(class_dir)]\n",
        "        all_images.extend(images)\n",
        "        all_labels.extend([class_name] * len(images))\n",
        "\n",
        "    # 70% train, 30% temp\n",
        "    train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(\n",
        "        all_images,\n",
        "        all_labels,\n",
        "        test_size=0.3,\n",
        "        stratify=all_labels,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # 15% val, 15% test\n",
        "    val_imgs, test_imgs, val_labels, test_labels = train_test_split(\n",
        "        temp_imgs,\n",
        "        temp_labels,\n",
        "        test_size=0.5,\n",
        "        stratify=temp_labels,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    for split_name, images, labels in [\n",
        "        ('train', train_imgs, train_labels),\n",
        "        ('validation', val_imgs, val_labels),\n",
        "        ('test', test_imgs, test_labels)\n",
        "    ]:\n",
        "        for img_path, label in zip(images, labels):\n",
        "            dest_dir = os.path.join(OUTPUT_DIR, split_name, label)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            shutil.copy(img_path, dest_dir)\n",
        "\n",
        "    print(f\"Train: {len(train_imgs)}\")\n",
        "    print(f\"Val:   {len(val_imgs)}\")\n",
        "    print(f\"Test:  {len(test_imgs)}\")\n",
        "\n",
        "split_dataset()  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
